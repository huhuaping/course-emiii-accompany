{
  "hash": "8f9b650bc368b54ae3479fc35769f7cd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"IV Application (I)\"\nsubtitle: \"Mother and father as IVs for education\"\n---\n\n\n## Case Description\n\n**Research Interests**: \n\n- With data set `wooldridge::mroz`, researchers were interest in the return (`log(Wage)`) to education (`edu`) for married women.\n\n- use both $motheduc$ or/and $fatheduc$ as instruments for $educ$.\n\n\n## Reproducible Sources\n\na. **Wooldridge, J.M. Introductory econometrics: a modern approach[M].** Seventh edition. Australia: Cengage, 2020.\n\na. **Hill C, Griffiths W E, Lim G C. Principles of econometrics[M]**. Fifth edition. NJ: John Wiley & Sons, 2018.\n\nb. **Colonescu C. Principles of Econometrics with R (2016)** <https://bookdown.org/ccolonescu/RPoE4/>\n\n\n\n## Learning Targets\n\na. Understand the nature of `Endogeneity`.\n\nb. Know the steps of running TSLS method.\n\nc. Be familiar with R package function `systemfit::systemfit()` and `ARE::ivreg()`.\n\nd. Testing **Instrument validity** (Weak instrument) both using **Restricted F-test** and **J-test**.\n\ne. Testing **Regressor endogeneity** by using **Hausman test**.\n\n\n## Exercise Materials \n\nYou can find all the exercise materials in this project under the file directory:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nD:/github/course-emiii-accompany/IV-wage-mroz\n├── code-mroz.R\n└── mroz-var-label.txt\n```\n\n\n:::\n:::\n\n\n\n## OLS Estimation\n\nConsider the following \"error specified\" wage model:\n\n$$\\begin{align}\nlwage_i = \\beta_1 +\\beta_2educ_i + \\beta_3exper_i +\\beta_4expersq_i + e_i\n\\end{align}$$\n\n## Two-stage least squares(TSLS): the solutions\n\n\nWe can conduct the **TSLS** procedure with following two solutions:\n\n- use the **\"Step-by-Step solution\"** methods without variance correction.\n\n- use the  **\"Integrated solution\"** with variance correction.\n\n\n(1) By doing the **Step-by-Step solution**, we will understand the basic procedure of Two-stage least squares(TSLS). But DO NOT use **Step-by-Step solution** solution in your paper! It is only for teaching purpose here.\n\n(2) We need a **Integrated solution** for following reasons:\n\n- We should obtain the correct estimated error for test and inference.\n\n- We should avoid tedious steps in the former **Step-by-Step** routine. When the model contains more than one endogenous regressors and there are lots available instruments, then the step-by-step solution will get extremely tedious.\n\nIn `R` ecosystem, we have two packages to execute the  integrated solution:\n\n- We can use `systemfit` package function `systemfit::systemfit()`.\n\n- Or we may use `ARE` package function `ARE::ivreg()`.\n\nBoth of these tools can conduct the integrated solution, and will adjust the variance of estimators automatically. \n\n\n## TWLS (Step-by-step solution): `mothereduc` as IV\n\nFor the **Step-by-step solution**, let's consider using mother education(`mothereduc`) as instrument variable for education(`educ`).\n\nwe can obtain the fitted variable $\\widehat{educ}$ by conduct the following **stage 1** OLS regression\n\n$$\\begin{align}\n\\widehat{educ} = \\hat{\\gamma}_1 +\\hat{\\gamma}_2exper + \\hat{\\gamma}_3expersq +\\hat{\\gamma}_4mothereduc \n\\end{align}$$\n\nIn the second stage, we will regress log(wage) on the $\\widehat{educ}$  from stage 1 and experience (`exper`)and its quadratic term (`expersq`).\n\n\n$$\\begin{align}\nlwage = \\hat{\\beta}_1 +\\hat{\\beta}_2\\widehat{educ} + \\hat{\\beta}_3exper +\\hat{\\beta}_4expersq + \\hat{\\epsilon}\n\\end{align}$$\n\n\n## TWLS (Integrated solution): `mothereduc` as IV\n\nLet's consider using $motheduc$ as the only instrument for $educ$ by using the **Integrated solution**.\n\n$$\\begin{cases}\n  \\begin{align}\n  \\widehat{educ} &= \\hat{\\gamma}_1 +\\hat{\\gamma}_2exper + \\hat{\\gamma}_3expersq +\\hat{\\gamma}_4motheduc  && \\text{(stage 1)}\\\\\n  lwage & = \\hat{\\beta}_1 +\\hat{\\beta}_2\\widehat{educ} + \\hat{\\beta}_3exper +\\hat{\\beta}_4expersq + \\hat{\\epsilon}  && \\text{(stage 2)}\n  \\end{align}\n\\end{cases}$$\n\nIn `R` ecosystem, we have two packages to execute the  integrated solution:\n\n- We can use `systemfit` package function `systemfit::systemfit()`.\n\n- Or we may use `ARE` package function `ARE::ivreg()`.\n\nBoth of these tools can conduct the integrated solution, and will adjust the variance of estimators correctly and automatically. \n\n\n## TWLS (Integrated solution): `mothereduc` as IV\n\nNow let's consider using $fatheduc$ as the only instrument for $educ$.\n\n$$\\begin{cases}\n  \\begin{align}\n  \\widehat{educ} &= \\hat{\\gamma}_1 +\\hat{\\gamma}_2exper + \\hat{\\gamma}_3expersq +\\hat{\\gamma}_4fatheduc  && \\text{(stage 1)}\\\\\n  lwage & = \\hat{\\beta}_1 +\\hat{\\beta}_2\\widehat{educ} + \\hat{\\beta}_3exper +\\hat{\\beta}_4expersq + \\hat{\\epsilon}  && \\text{(stage 2)}\n  \\end{align}\n\\end{cases}$$\n\nWe will repeat the whole procedure by using  `R` function `systemfit::systemfit()` or `ARE::ivreg()` as we have done before.\n\n## TWLS (Integrated solution): `mothedu` and `fatheduc` as IV\n\nAlso, we can use both $motheduc$ and $fatheduc$ as instruments for $educ$.\n\n$$\\begin{cases}\n  \\begin{align}\n  \\widehat{educ} &= \\hat{\\gamma}_1 +\\hat{\\gamma}_2exper + \\hat{\\beta}_3expersq +\\hat{\\beta}_4motheduc + \\hat{\\beta}_5fatheduc  && \\text{(stage 1)}\\\\\n  lwage & = \\hat{\\beta}_1 +\\hat{\\beta}_2\\widehat{educ} + \\hat{\\beta}_3exper +\\hat{\\beta}_4expersq + \\hat{\\epsilon}  && \\text{(stage 2)}\n  \\end{align}\n\\end{cases}$$\n\nWe will repeat the whole procedure by using  `R` function `systemfit::systemfit()` or `ARE::ivreg()` as we have done before.\n\n## Solutions comparison: a glance\n\nUntil now, we obtain totally **Five** estimation results with different model settings or solutions:\n\na. Error specification model with OLS regression directly.\n\nb. (**Step-by-Step solution**) Explicit 2SLS estimation **without** variance correction (IV regression step by step with only $matheduc$ as instrument).\n\nc. (**Integrated solution**) Dedicated IV estimation **with** variance correction ( using `R` tools of `systemfit::systemfit()` or `ARE::ivreg()`).\n\n- The IV model with only \n$motheduc$ as instrument for endogenous variable $edu$\n\n- The IV model with only \n$fatheduc$ as instrument for endogenous variable $edu$\n\n- The IV model with  both \n$motheduc$ and \n$fatheduc$ as instruments for endogenous variable $edu$\n\nAfter the empirical comparison, we can push to further thinking with these results.\n\n- Which estimation is the best? \n\n- How to judge and evaluate different instrument choices? \n\n## Testing Instrument validity\n\nConsider the general model\n\n$$\\begin{align}\nY_{i}=\\beta_{0}+\\sum_{j=1}^{k} \\beta_{j} X_{j i}+\\sum_{s=1}^{r} \\beta_{k+s} W_{ri}+\\epsilon_{i}\n\\end{align}$$\n\n> - $Y_{i}$ is the dependent variable\n- $\\beta_{0}, \\ldots, \\beta_{k+1}$ are $1+k+r$ unknown regression coefficients\n- $X_{1 i}, \\ldots, X_{k i}$ are $k$ endogenous regressors\n- $W_{1 i}, \\ldots, W_{r i}$ are $r$ exogenous regressors which are uncorrelated with $u_{i}$\n- $u_{i}$ is the error term\n- $Z_{1 i}, \\ldots, Z_{m i}$ are $m$ instrumental variables\n\nAs we know, valid instruments should satisfy both **Relevance condition** and **Exogeneity condition**.\n\n$$\n\\begin{aligned}\n&E\\left(Z_{i} X_{i}^{\\prime}\\right) \\neq 0 & \\quad \\text{(Relevance)}\\\\\n&E\\left(Z_{i} \\epsilon_{i}\\right)=0 &\\quad \\text{(Exogeneity)}\n\\end{aligned}\n$$\n\n### Weak instrument: Restricted F-test\n\nIn case with a **single** endogenous regressor, we can take the  **F-test** to check the **Weak instrument**.\n\nThe basic idea of the F-test is very simple:\n\nIf the estimated coefficients of **all instruments** in the **first-stage** of a 2SLS estimation are **zero**, the instruments do not explain any of the variation in the \n$X$ which clearly violates the relevance assumption. \n\nWe may use the following rule of thumb:\n\n- Conduct the **first-stage regression** of a 2SLS estimation\n\n$$\\begin{align}\nX_{i}=\\hat{\\gamma}_{0}+\\hat{\\gamma}_{1} W_{1 i}+\\ldots+\\hat{\\gamma}_{p} W_{p i}+ \\hat{\\theta}_{1} Z_{1 i}+\\ldots+\\hat{\\theta}_{q} Z_{q i}+v_{i} \\quad \\text{(3)}\n\\end{align}$$\n\n- Test the restricted joint hypothesis \n$H_0: \\hat{\\theta}_1=\\ldots=\\hat{\\theta}_q=0$ by compute the\n$F$-statistic. \n\n- If the\n$F$-statistic is less than  critical value, the instruments are **weak**. \n\nThe rule of thumb is easily implemented in `R`. Run the first-stage regression using `lm()` and subsequently compute the restricted $F$-statistic by `R` function of `car::linearHypothesis()`. \n\nFor all  three IV model, we can test instrument(s) relevance respectively.\n\n$$\\begin{align}\neduc &= \\gamma_1 +\\gamma_2exper +\\gamma_2expersq + \\theta_1motheduc  +v \n&& \\text{(relevance test 1)}\\\\\neduc &= \\gamma_1 +\\gamma_2exper +\\gamma_2expersq + \\theta_2fatheduc +v  \n&& \\text{(relevance test 2)} \\\\\neduc &= \\gamma_1 +\\gamma_2exper +\\gamma_2expersq + \\theta_1motheduc + \\theta_2fatheduc +v  \n&& \\text{(relevance test 3)}\n\\end{align}$$\n\n### Weak instrument: Cragg-Donald test\n\nThe former test for weak instruments might be unreliable with **more than** one endogenous regressor, though, because there is indeed one\n$F$-statistic for each endogenous regressor. \n\nAn alternative is the **Cragg-Donald test** based on the following statistic:\n\n$$\\begin{align}\nF=\\frac{N-G-B}{L} \\frac{r_{B}^{2}}{1-r_{B}^{2}}\n\\end{align}$$\n\nwhere:\n\n- $G$ is the number of exogenous regressors;\n\n- $B$ is the number of endogenous regressors;\n\n- $L$ is the number of external instruments;\n\n- $r_B$ is the lowest canonical correlation.\n\n> **Canonical correlation** is a measure of the correlation between the endogenous and the exogenous variables, which can be calculated by the function `cancor()` in  `R`.\n\n\nThe critical value can be found in table 10E.1 at: Hill C, Griffiths W, Lim G. Principles of econometrics[M]. John Wiley \\& Sons, 2018.\n\n### Instrument Exogeneity: J-test\n\n**Instrument Exogeneity** means all \n$m$ instruments must be uncorrelated with the error term,\n\n$$Cov{(Z_{1 i}, \\epsilon_{i})}=0; \\quad \\ldots; \\quad Cov{(Z_{mi}, \\epsilon_{i})}=0.$$\n\n- In the context of the simple IV estimator, we will find that the exogeneity requirement **can not** be tested. (Why?)\n\n- However, if we have more instruments than we need, we can effectively test whether **some of** them are uncorrelated with the structural error.\n\nUnder **over-identification** \n$(m>k)$, consistent IV estimation with (multiple) different combinations of instruments is possible. \n\n> If instruments are exogenous, the obtained estimates should be **similar**. \n\n> If estimates are very **different**, some or all instruments may .red[not] be exogenous.\n\nThe **Overidentifying Restrictions Test** (**J test**) formally check this.\n\n- The null hypothesis is Instrument Exogeneity.\n\n$$H_{0}: E\\left(Z_{h i} \\epsilon_{i}\\right)=0, \\text { for all } h=1,2, \\dots, m$$\n\nThe **overidentifying restrictions test** (also called the  $J$-test, or **Sargan test**) is an approach to test the hypothesis that the additional instruments are exogenous.\n\nProcedure of overidentifying restrictions test is:\n\n- **Step 1**: Compute the **IV regression residuals** :\n\n$$\\widehat{\\epsilon}_{i}^{IV}=Y_{i}-\\left(\\hat{\\beta}_{0}^{ IV}+\\sum_{j=1}^{k} \\hat{\\beta}_{j}^{IV} X_{j i}+\\sum_{s=1}^{r} \\hat{\\beta}_{k+s}^{IV} W_{s i}\\right)$$\n\n- **Step 2**: Run the **auxiliary regression**: regress the IV residuals on instruments and exogenous regressors. And test the joint hypothesis \n$H_{0}: \\alpha_{1}=0, \\ldots, \\alpha_{m}=0$\n\n$$\\widehat{\\epsilon}_{i}^{IV}=\\theta_{0}+\\sum_{h=1}^{m} \\theta_{h} Z_{h i}+\\sum_{s=1}^{r} \\gamma_{s} W_{s i}+v_{i} \\quad \\text{(2)}$$\n\n- **Step3**: Compute the **J statistic**:\n$J=m F$\n\n> where \n$F$ is the F-statistic of the \n$m$ restrictions \n$H_0: \\theta_{1}=\\ldots=\\theta_{m}=0$ in eq(2)\n\nUnder the **null hypothesis**, \n$J$ statistic is distributed as \n$\\chi^{2}(m-k)$ approximately for large samples.\n\n$$\\boldsymbol{J} \\sim \\chi^{2}({m-k})$$\n\n> IF $J$ is **less** than **critical value**, it means that all instruments are .red[ex]ogenous. \n\n> IF $J$ is **larger** than **critical value**, it mean that some of the instruments are .red[en]ogenous. \n\n- We can apply the  $J$-test by using `R` function `linearHypothesis()`.\n\nAgain, we can use both $matheduc$ and $fatheduc$ as instruments for $educ$.\n\nThus, the IV model is over-identification, and we can test the exogeneity of both these two instruments by using **J-test**.\n\nThe 2SLS model will be set as below.\n\n$$\\begin{cases}\n  \\begin{align}\n  \\widehat{educ} &= \\hat{\\gamma}_1 +\\hat{\\gamma}_2exper + \\hat{\\beta}_3expersq +\\hat{\\beta}_4motheduc + \\hat{\\beta}_5fatheduc  && \\text{(stage 1)}\\\\\n  lwage & = \\hat{\\beta}_1 +\\hat{\\beta}_2\\widehat{educ} + \\hat{\\beta}_3exper +\\hat{\\beta}_4expersq + \\hat{\\epsilon}  && \\text{(stage 2)}\n  \\end{align}\n\\end{cases}$$\n\nAnd the auxiliary regression should be\n\n$$\\begin{align}\n  \\hat{\\epsilon}^{IV} &= \\hat{\\alpha}_1 +\\hat{\\alpha}_2exper + \\hat{\\alpha}_3expersq +\\hat{\\theta}_1motheduc + \\hat{\\theta}_2fatheduc  + v && \\text{(auxiliary model)}\n  \\end{align}$$\n  \nFinally, We can calculate J-statistic by hand or obtain it by using special tools.\n\n\n- Calculate J-statistic by hand \n\n- using tools of  `linearHypothesis(.,  test = \"Chisq\")` \n\n## Testing Regressor endogeneity\n\nHow can we test the regressor endogeneity?\n\nSince OLS is in general more efficient than IV (recall that if Gauss-Markov assumptions hold OLS is BLUE), we don't want to use IV when we don't need to get the consistent estimators. \n\nOf course, if we really want to get a consistent estimator, we also need to check whether the endogenous regressors are really **endogenous** in the model.\n\nSo we should test following hypothesis:\n\n$$H_{0}: \\operatorname{Cov}(X, \\epsilon)=0 \\text { vs. } H_{1}: \\operatorname{Cov}(X, \\epsilon) \\neq 0$$\n\n###  Hausman test\n\n`Hausman` tells us that we should use OLS if we fail to reject \n$H_{0}$. And we should use IV estimation if we reject \n$H_{0}$ \n\nLet's see how to construct a `Hausman test`. While the idea is very simple.\n\n- If \n$X$ is **.red[ex]ogenous** in fact, then both OLS and IV are consistent, but OLS estimates are more efficient than IV estimates.\n\n- If \n$X$ is **.red[en]dogenous** in fact, then the results from OLS estimators are different, while results obtained by IV (eg. 2SLS) are consistent.\n\nWe can compare the difference between estimates computed using both OLS and IV. \n\n- If the difference is **small**, we can conjecture that both OLS and IV are consistent and the small difference between the estimates is not systematic. \n- If the difference is **large** this is due to the fact that OLS estimates are not consistent. We should use IV in this case.\n\nAgain, we use both $matheduc$ and $fatheduc$ as instruments for $educ$ in our IV model setting.\n\n$$\\begin{cases}\n  \\begin{align}\n  \\widehat{educ} &= \\hat{\\gamma}_1 +\\hat{\\gamma}_2exper + \\hat{\\beta}_3expersq +\\hat{\\beta}_4motheduc + \\hat{\\beta}_5fatheduc  && \\text{(stage 1)}\\\\\n  lwage & = \\hat{\\alpha}_1 +\\hat{\\alpha}_2\\widehat{educ} + \\hat{\\alpha}_3exper +\\hat{\\alpha}_4expersq + \\hat{\\epsilon}  && \\text{(stage 2)}\n  \\end{align}\n\\end{cases}$$\n\n::: {.callout-tips}\n\nIn `R`, we can use IV model diagnose tool to check the Hausman test results.\n\nIn fact, `R` function `summary(lm_iv_mf, diagnostics = TRUE)` by setting `diagnostics = TRUE` will give you these results.\n\n:::\n",
    "supporting": [
      "iv-wage-mroz_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}